# -*- coding: utf-8 -*-
"""Copy of ECG_Anomaly_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VolyJBM6FYcxDOnbFIucb9Ycozh10qx4

##Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from zipfile import ZipFile
!pip install plotly
import plotly.graph_objects as go
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns

"""##Dataset Collection
###ECG500 Dataset
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

!wget https://www.timeseriesclassification.com/aeon-toolkit/ECG5000.zip

"""##Data Transformation"""

with ZipFile('ECG5000.zip', 'r') as zip :
   zip.extractall(path='/content/dataset')

df1 = pd.read_csv('/content/dataset/ECG5000_TRAIN.txt', sep='\s+', header=None)
df1.head()

df1.shape

df1.info()

df2 = pd.read_csv('/content/dataset/ECG5000_TEST.txt', sep='\s+', header=None)
df2.head()

df2.info()

df = pd.concat([df1, df2])
df.sample(5)

df.info()

df = df.add_prefix('c')
df.sample(5)

df['c0'].value_counts()

"""##Importing Tensorflow Functions"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler

import tensorflow as tf
from tensorflow.keras.models import Model

x_train, x_test, y_train, y_test = train_test_split(df.values, df.values[:,0:1], test_size=0.2, random_state=42)
scaler = MinMaxScaler()
data_scaled = scaler.fit(x_train)

x_train_scaled = data_scaled.transform(x_train)
x_test_scaled = data_scaled.transform(x_test)

x_train_scaled

normal_train = pd.DataFrame(x_train_scaled).add_prefix('c').query('c0 == 0').values[:,1:]
annomaly_train = pd.DataFrame(x_train_scaled).add_prefix('c').query('c0 > 0').values[:,1:]

normal_test = pd.DataFrame(x_test_scaled).add_prefix('c').query('c0 == 0').values[:,1:]
annomaly_test = pd.DataFrame(x_test_scaled).add_prefix('c').query('c0 > 0').values[:,1:]

"""##Representation of Difference b/w Normal and Abnormal Scale Values"""

feature1_idx = 0
feature2_idx = 50
feature3_idx = 100

fig_normal = go.Figure(data=[go.Scatter3d(
    x=normal_train[:, feature1_idx],
    y=normal_train[:, feature2_idx],
    z=normal_train[:, feature3_idx],
    mode='markers',
    marker=dict(
        size=5,
        color='blue',
        colorscale='Viridis',
        opacity=0.8
    )
)])
fig_normal.update_layout(title='Normal ECG Data',
                  scene=dict(
                      xaxis_title='Feature 1',
                      yaxis_title='Feature 2',
                      zaxis_title='Feature 3'),
                      width=600,
                      height=500)

fig_normal.show()

fig_anomaly = go.Figure(data=[go.Scatter3d(
    x=annomaly_train[:, feature1_idx],
    y=annomaly_train[:, feature2_idx],
    z=annomaly_train[:, feature3_idx],
    mode='markers',
    marker=dict(
        size=5,
        color='red',
        colorscale='Viridis',
        opacity=0.8
    )
)])

fig_anomaly.update_layout(title='Anomaly ECG Data',
                  scene=dict(
                      xaxis_title='Feature 1',
                      yaxis_title='Feature 2',
                      zaxis_title='Feature 3'),
                  width=600,
                  height=500)
fig_anomaly.show()

normal_sample = normal_train[0]
anomaly_sample = annomaly_train[0]

fig = go.Figure(data=[go.Scatter3d(
    x=list(range(len(normal_sample))),
    y=normal_sample,
    z=[0] * len(normal_sample),
    mode='markers',
    name='Normal'
),
go.Scatter3d(
    x=list(range(len(anomaly_sample))),
    y=anomaly_sample,
    z=[1] * len(anomaly_sample),
    mode='markers',
    name='Anomaly'
)])

fig.update_layout(title='Normal vs Anomaly ECG Signals',
                  scene=dict(xaxis_title='Time', yaxis_title='Amplitude', zaxis_title='Category'), width=700, height=600)

fig.show()

plt.plot(normal_train[0])
plt.plot(normal_train[1])
plt.plot(normal_train[2])

plt.plot(annomaly_train[0])
plt.plot(annomaly_train[1])
plt.plot(annomaly_train[2])

"""##Autoencoder Model Architecture"""

class AutoEncoder(Model) :
  def __init__(self) :
    super(AutoEncoder, self).__init__()
    self.encoder = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(8, activation='relu')])

    self.decoder = tf.keras.Sequential([
        tf.keras.layers.Dense(16, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(140,activation='sigmoid')])

  def call(self, x) :
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

model = AutoEncoder()
early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',
                                                  patience=2,
                                                  mode = 'min')
model.compile(optimizer = 'adam', loss = 'mae')

history = model.fit(normal_train, normal_train,
                    epochs=50,
                    batch_size=128,
                    validation_data=(x_train_scaled[:,1:], x_train_scaled[:,1:]),
                    shuffle=True,
                    callbacks=[early_stopping]
                    )

"""##Model Summary"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title("Model Loss")
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc = 'upper left')
plt.show()

model.summary()

encoder = model.encoder(normal_test).numpy()
decoder = model.decoder(encoder).numpy()

encoder.shape

decoder.shape

"""##Reconstruction of the values to Normal Scales"""

plt.plot(normal_test[0],'b')
plt.plot(decoder[0],'r')

reconstruction_normal = model.predict(normal_test)
train_loss_normal = tf.keras.losses.mae(reconstruction_normal, normal_test)

plt.hist(train_loss_normal, bins=50)

np.mean(train_loss_normal)

np.std(train_loss_normal)

threshold = np.mean(train_loss_normal) + 2*np.std(train_loss_normal)
threshold

reconstruction_annomaly = model.predict(annomaly_test)
train_loss_annomaly = tf.keras.losses.mae(reconstruction_annomaly, annomaly_test)

plt.hist(train_loss_annomaly, bins=50)

import numpy as np
import tensorflow as tf
import plotly.graph_objects as go

def calculate_accuracy_and_plot(train_loss_annomaly, threshold, normal_test, annomaly_test):

    predictions = (train_loss_annomaly.numpy() > threshold).astype(int)
    accuracy = np.sum(predictions) / len(predictions) * 100


    fig = go.Figure()

    fig.add_trace(go.Scatter3d(
        x=normal_test[:, 0],
        y=normal_test[:, 1],
        z=train_loss_normal,
        mode='markers',
        name='Normal',
        marker=dict(
            size=5,
            color=train_loss_normal,
            colorscale='Viridis',
            opacity=0.8
        )
    ))

    fig.add_trace(go.Scatter3d(
        x=annomaly_test[:, 0],
        y=annomaly_test[:, 1],
        z=train_loss_annomaly.numpy(),
        mode='markers',
        name='Anomaly',
        marker=dict(
            size=5,
            color=train_loss_annomaly.numpy(),
            colorscale='Viridis',
            opacity=0.8
        )
    ))

    x_plane = np.linspace(np.min(normal_test[:, 0]), np.max(normal_test[:, 0]), 10)
    y_plane = np.linspace(np.min(normal_test[:, 1]), np.max(normal_test[:, 1]), 10)
    z_plane = np.full((10, 10), threshold)
    fig.add_surface(x=x_plane, y=y_plane, z=z_plane, showscale=False, opacity=0.5, name='Threshold')

    fig.update_layout(title="Accuracy: {:.2f}%".format(accuracy),
                      scene=dict(xaxis_title='Feature 1', yaxis_title='Feature 2', zaxis_title='Reconstruction Error'),
                      width=800, height=600)

    fig.show()

calculate_accuracy_and_plot(train_loss_annomaly, threshold, normal_test, annomaly_test)

np.mean(train_loss_annomaly)

np.std(train_loss_annomaly)

tf.math.less(train_loss_normal, threshold)

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

x = np.arange(len(train_loss_normal))
y = np.zeros_like(x)
z = train_loss_normal

colors = ['blue' if val else 'red' for val in tf.math.less(train_loss_normal, threshold)]

ax.scatter(x, y, z, c=colors)

ax.set_xlabel('Index')
ax.set_ylabel('Y')
ax.set_zlabel('Loss')
plt.title('3D Plot of Loss with Threshold')
plt.show()

import seaborn as sns
train_loss_normal_2d = tf.reshape(train_loss_normal, [1, -1])
sns.heatmap(train_loss_normal_2d)

preds = tf.math.less(train_loss_normal, threshold)

tf.math.count_nonzero(preds)

preds.shape

preds_annnomaly = tf.math.greater(train_loss_annomaly, threshold)
tf.math.count_nonzero(preds_annnomaly)

preds_annnomaly.shape

"""##Representation of True Values and False Values"""

plt.hist(train_loss_normal, bins=50, label='Normal')
plt.hist(train_loss_annomaly, bins=50, label='Anomaly')
plt.axvline(threshold, color='r',linewidth=3, linestyle='dashed', label='{:0.3f}'.format(threshold))
plt.legend(loc='upper right')
plt.show()

def plot_3d_loss(train_loss_normal, train_loss_anomaly):

  x = np.arange(train_loss_normal.shape[0])

  fig_normal = go.Figure(data=[go.Scatter3d(
      x=x,
      y=np.zeros_like(x),
      z=train_loss_normal.numpy().flatten(),
      mode='markers',
      marker=dict(
          size=5,
          color='blue',
          colorscale='Viridis',
          opacity=0.8
      )
  )])

  fig_normal.update_layout(title='Reconstruction Loss for Normal Data',
                    scene=dict(
                        xaxis_title='Sample Index',
                        yaxis_title='Feature Index',
                        zaxis_title='Reconstruction Loss'),
                        width=600,
                        height=500)

  x = np.arange(train_loss_anomaly.shape[0])

  fig_anomaly = go.Figure(data=[go.Scatter3d(
      x=x,
      y=np.zeros_like(x),
      z=train_loss_anomaly.numpy().flatten(),
      mode='markers',
      marker=dict(
          size=5,
          color='red',
          colorscale='Viridis',
          opacity=0.8
      )
  )])

  fig_anomaly.update_layout(title='Reconstruction Loss for Anomaly Data',
                    scene=dict(
                        xaxis_title='Sample Index',
                        yaxis_title='Feature Index',
                        zaxis_title='Reconstruction Loss'),
                        width=600,
                        height=500)

  fig_normal.show()
  fig_anomaly.show()

plot_3d_loss(train_loss_normal, train_loss_annomaly)

def plot_3d_loss_diff(train_loss_normal, train_loss_anomaly):

  min_length = min(train_loss_normal.shape[0], train_loss_anomaly.shape[0])
  difference = train_loss_anomaly[:min_length] - train_loss_normal[:min_length]

  x = np.arange(min_length)

  fig_diff = go.Figure(data=[go.Scatter3d(
      x=x,
      y=np.zeros_like(x),
      z=difference.numpy().flatten(),
      mode='markers',
      marker=dict(
          size=5,
          color=difference.numpy().flatten(),
          colorscale='Viridis',
          opacity=0.8
      )
  )])

  fig_diff.update_layout(title='Difference in Reconstruction Loss (Anomaly - Normal)',
                    scene=dict(
                        xaxis_title='Sample Index',
                        yaxis_title='Feature Index',
                        zaxis_title='Loss Difference'),
                        width=700,
                        height=600)

  fig_diff.show()

plot_3d_loss_diff(train_loss_normal, train_loss_annomaly)

## Confusion Matrix Implementation

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

y_true = (y_test.flatten() > 1.0).astype(int)

reconstruction_test = model.predict(x_test_scaled[:, 1:])  # Predict on test set features
# Calculate Mean Absolute Error (MAE) for each sample
mae_test = tf.keras.losses.mae(reconstruction_test, x_test_scaled[:, 1:]).numpy()
# Apply threshold to determine anomalies
y_pred = (mae_test > threshold).astype(int)

# Step 3: Compute Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:")
print(cm)

# Step 4: Classification Report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=['Normal', 'Anomaly']))

# Step 5: Visualize Confusion Matrix
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Anomaly'],
            yticklabels=['Normal', 'Anomaly'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import roc_curve, auc

  fpr, tpr, thresholds = roc_curve(y_true, mae_test)
  roc_auc = auc(fpr, tpr)

  plt.figure()
  plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver Operating Characteristic')
  plt.legend(loc="lower right")
  plt.show()

from sklearn.metrics import precision_recall_curve

  precision, recall, thresholds_pr = precision_recall_curve(y_true, mae_test)

  plt.figure()
  plt.plot(recall, precision, marker='.')
  plt.xlabel('Recall')
  plt.ylabel('Precision')
  plt.title('Precision-Recall Curve')
  plt.show()

